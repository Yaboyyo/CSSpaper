{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch pandas transformers scikit-learn tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVl0QuQHhJCz",
        "outputId": "459468d9-6ebe-4795-8eed-21369e5e6340"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        # Move the model to GPU as soon as it is loaded\n",
        "        self.bert_model.to('cuda')\n",
        "        self.bert_model.eval()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data.iloc[idx]['headline']\n",
        "        label = self.data.iloc[idx]['clickbait']\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        # Directly process and move tensors to GPU\n",
        "        inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = self.bert_model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "        # Convert label to tensor and move to GPU\n",
        "        return embeddings.squeeze(), torch.tensor(label).to('cuda')\n"
      ],
      "metadata": {
        "id": "F1zAh5CMhJ1H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QZPMiwLO0KeH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(torch.nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x.unsqueeze(1))  # unsqueeze to add a fake sequence length dimension\n",
        "        return self.fc(hn.squeeze())\n"
      ],
      "metadata": {
        "id": "-VRsHZxe0LUo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    with torch.no_grad():\n",
        "        for embeddings, labels in dataloader:\n",
        "            embeddings, labels = embeddings.to('cuda'), labels.to('cuda')\n",
        "            outputs = model(embeddings)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            true_labels.extend(labels.cpu().tolist())\n",
        "            pred_labels.extend(predicted.cpu().tolist())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
        "    acc = accuracy_score(true_labels, pred_labels)\n",
        "    return avg_loss, f1, acc\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, test_dataloader, epochs):\n",
        "    print(\"Starting training...\")\n",
        "    model = model.to('cuda')\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_model_path = 'best_model.pth'  # Define path to save the best model\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        model.train()\n",
        "        true_labels = []\n",
        "        pred_labels = []\n",
        "\n",
        "        for embeddings, labels in train_dataloader:\n",
        "            embeddings, labels = embeddings.to('cuda'), labels.to('cuda')\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(embeddings)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            true_labels.extend(labels.cpu().tolist())\n",
        "            pred_labels.extend(predicted.cpu().tolist())\n",
        "\n",
        "        train_f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
        "        train_acc = accuracy_score(true_labels, pred_labels)\n",
        "        val_loss, val_f1, val_acc = evaluate(model, val_dataloader, criterion)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Training Loss: {loss.item()}, Training F1: {train_f1:.4f}, Training Acc: {train_acc:.4f}\")\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}, Validation Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Save the best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(\"Saved best model\")\n",
        "\n",
        "    # Load the best model for testing\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    test_loss, test_f1, test_acc = evaluate(model, test_dataloader, criterion)\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test F1: {test_f1:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "# Example usage:\n",
        "# train(model, train_loader, val_loader, test_loader, epochs=10)\n"
      ],
      "metadata": {
        "id": "kxZwJszI0OrO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data = pd.read_csv('clickbait_data.csv')\n",
        "# Split the data into training and remaining data\n",
        "train_data, remaining_data = train_test_split(data, test_size=0.4, random_state=42)\n",
        "\n",
        "# Split the remaining data into validation and test data\n",
        "val_data, test_data = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
        "\n",
        "model = LSTMClassifier(embedding_dim=768, hidden_dim=128, output_dim=2).to('cuda')\n",
        "train_dataloader = DataLoader(TextDataset(train_data), batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(TextDataset(val_data), batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(TextDataset(test_data), batch_size=16, shuffle=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "train(model, train_dataloader, val_dataloader, test_dataloader, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhDVxJA90Yq-",
        "outputId": "49696639-166b-4706-a1f5-897bd3f158cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [04:40<42:07, 280.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 0.0028090483974665403, Training F1: 0.9706, Training Acc: 0.9706\n",
            "Validation Loss: 0.0675, Validation F1: 0.9769, Validation Acc: 0.9769\n",
            "Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [09:16<37:01, 277.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Training Loss: 0.007919272407889366, Training F1: 0.9798, Training Acc: 0.9798\n",
            "Validation Loss: 0.0585, Validation F1: 0.9811, Validation Acc: 0.9811\n",
            "Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [13:52<32:18, 276.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Training Loss: 0.013588412664830685, Training F1: 0.9833, Training Acc: 0.9833\n",
            "Validation Loss: 0.0574, Validation F1: 0.9809, Validation Acc: 0.9809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [18:28<27:39, 276.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Training Loss: 0.0008541347342543304, Training F1: 0.9876, Training Acc: 0.9876\n",
            "Validation Loss: 0.0610, Validation F1: 0.9828, Validation Acc: 0.9828\n",
            "Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [23:03<23:00, 276.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Training Loss: 0.012171884067356586, Training F1: 0.9915, Training Acc: 0.9915\n",
            "Validation Loss: 0.0653, Validation F1: 0.9791, Validation Acc: 0.9791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [27:38<18:22, 275.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Training Loss: 0.0003630506689660251, Training F1: 0.9931, Training Acc: 0.9931\n",
            "Validation Loss: 0.0609, Validation F1: 0.9844, Validation Acc: 0.9844\n",
            "Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [32:12<13:45, 275.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Training Loss: 0.002676372416317463, Training F1: 0.9956, Training Acc: 0.9956\n",
            "Validation Loss: 0.0655, Validation F1: 0.9825, Validation Acc: 0.9825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [36:47<09:10, 275.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Training Loss: 0.04988257586956024, Training F1: 0.9964, Training Acc: 0.9964\n",
            "Validation Loss: 0.0920, Validation F1: 0.9775, Validation Acc: 0.9775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [41:24<04:35, 275.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Training Loss: 0.0008059106767177582, Training F1: 0.9968, Training Acc: 0.9968\n",
            "Validation Loss: 0.0740, Validation F1: 0.9830, Validation Acc: 0.9830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [45:58<00:00, 275.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Training Loss: 0.0018734449986368418, Training F1: 0.9995, Training Acc: 0.9995\n",
            "Validation Loss: 0.0867, Validation F1: 0.9819, Validation Acc: 0.9819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0544, Test F1: 0.9819, Test Acc: 0.9819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Eb92hN-0rSr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}